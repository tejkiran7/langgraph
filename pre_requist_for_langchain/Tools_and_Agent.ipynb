{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "SERPER_API_KEY=os.getenv('SERPER_API_KEY')\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=LANGCHAIN_PROJECT\n",
    "os.environ[\"SERPER_API_KEY\"]=SERPER_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\langgraph\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\langgraph\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predefine tools</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval Augmented Generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \n",
      "Use cases include providing chatbot access to internal company data or giving factual information only from an authoritative source.\n",
      "\n",
      "\n",
      "\n",
      "Page: DataStax\n",
      "Summary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "print(tool.run({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=RB7o_mllE24&pp=ygUHQmUgUmljaA%3D%3D', 'https://www.youtube.com/watch?v=un9lZjJH-g4&pp=ygUHQmUgUmljaA%3D%3D']\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool\n",
    "tool2=YouTubeSearchTool()\n",
    "tool2.run(\"Be Rich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://en.wikipedia.org/wiki/K._E._Gnanavel_Raja',\n",
       "  'content': 'Neha Gnanavelraja: K. E. Gnanavel Raja (born 23 January 1986) is an Indian film producer from Tamil Nadu, India. He initially began his career by producing and distributing films starring Suriya and Karthi, before branching out to own two studios — Studio Green and Aadnah Arts [1] Personal life'},\n",
       " {'url': 'https://in.bookmyshow.com/person/k-e-gnanavel-raja/IEIN035106',\n",
       "  'content': 'K. E. Gnanavel Raja is an Indian film producer, who is the owner of the production and distribution company Studio Green, based in Chennai. Under the banner of this company, he has produced several hit movies like Sillunu Oru Kaadhal, Paruthiveeran, Singam, Siruthai, All in All Azhagu Raja, Madras, Biriyani, and Indru Netru Naalai, being the most popular ones.'},\n",
       " {'url': 'https://www.veethi.com/india-people/k._e._gnanavel_raja-profile-12098-14.htm',\n",
       "  'content': 'K. E. Gnanavel Raja Biography . K. E. Gnanavel Raja is a film producer, distributor and entrepreneur from Tamil Nadu. His career began with distributing Tamil films starring Suriya and Karthi, and later he started three film studios - Studio Green, Aadnah Arts and Blue Ghost Pictures, started in the years -2006, 2015 and 2017 respectively, and all these three studios are live.'},\n",
       " {'url': 'https://celebrityborns.com/biography/k-e-gnanavel-raja/15803',\n",
       "  'content': 'Short Biography. K. E. Gnanavel Raja was born on 30-06-1986 in Chennai in the state of Tamil Nadu, India. He is an Indian Film Producer, Film Distributor & Entrepreneur who is known for his work in Tamil & Telugu cinema.'},\n",
       " {'url': 'https://indianexpress.com/article/entertainment/tamil/gnanavel-raja-on-suriya-42-ss-rajamouli-is-the-reason-behind-the-films-huge-budget-8508745/',\n",
       "  'content': \"Producer Gnanavel Raja of Studio Green, who has produced films like Paruthiveeran, Singam, Siruthai, and Madras, is teaming up with his frequent collaborator Suriya for a film, which is tentatively titled Suriya 42. In a recent interview with a YouTube channel, Gnanavel said the upcoming film is the most lavish project in Suriya's career, and it is thrice the budget of his biggest movie\"}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tool = TavilySearchResults()\n",
    "tool.invoke({\"query\": \"who is gnanavelraja?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create a Custom tool</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_length.invoke(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_length.invoke(\"sunny savita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def summation(a: int, b: int) -> int:\n",
    "    \"\"\"Adding two numbers.\"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"a\":3,\"b\":9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation.invoke({'a':4,'b':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept of Agents<br>\n",
    "This Agent class from the first version of LangChain(lagacy)<br>\n",
    "they updated it towards the different classes<br>\n",
    "https://python.langchain.com/docs/concepts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools \n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=load_tools([\"wikipedia\"],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJKIRAN\\AppData\\Local\\Temp\\ipykernel_13456\\2645007812.py:1: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  agent=initialize_agent(tool,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n"
     ]
    }
   ],
   "source": [
    "agent=initialize_agent(tool,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEJKIRAN\\AppData\\Local\\Temp\\ipykernel_13456\\1212027048.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  agent.run(\"what is llama and who create this llm model?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to look up \"llama\" on Wikipedia to find information about it and its creators. \n",
      "Action: wikipedia\n",
      "Action Input: llama (large language model)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Llama (language model)\n",
      "Summary: Llama (Large Language Model Meta AI, formerly stylized as LLaMA) is a family of autoregressive large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 3.2, released in September 2024.\n",
      "Model weights for the first version of Llama were made available to the research community under a non-commercial license, and access was granted on a case-by-case basis. Unauthorized copies of the model were shared via BitTorrent. In response, Meta AI issued DMCA takedown requests against repositories sharing the link on GitHub. Subsequent versions of Llama were made accessible outside academia and released under licenses that permitted some commercial use. Llama models are trained at different parameter sizes, ranging between 1B and 405B. Originally, Llama was only available as a foundation model. Starting with Llama 2, Meta AI started releasing instruction fine-tuned versions alongside foundation models.\n",
      "Alongside the release of Llama 3, Meta added virtual assistant features to Facebook and WhatsApp in select regions, and a standalone website. Both services use a Llama 3 model.\n",
      "\n",
      "Page: Large language model\n",
      "Summary: A large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.\n",
      "The largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks, or be guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data on which they are trained.\n",
      "\n",
      "\n",
      "\n",
      "Page: Llama.cpp\n",
      "Summary: llama.cpp is an open source software library written mostly in C++ that performs inference on various large language models such as Llama. It is co-developed alongside the GGML project, a general-purpose tensor library. \n",
      "Command-line tools are included with the library, alongside a server with a simple web interface.\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now know that Llama is a family of large language models created by Meta AI. \n",
      "Final Answer: Llama is a family of large language models created by Meta AI.  \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Llama is a family of large language models created by Meta AI.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"what is llama and who create this llm model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Tool Calling Agent refers to an AI system or framework that dynamically invokes external tools or APIs to accomplish tasks as part of its decision-making process. Instead of relying solely on internal reasoning or knowledge, the agent calls specific tools to perform actions like calculations, searches, or other operations. This type of agent is often used in real-world applications where tasks require interaction with external systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.weatherapi.com/',\n",
       "  'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1731834826, 'localtime': '2024-11-17 01:13'}, 'current': {'last_updated_epoch': 1731834000, 'last_updated': '2024-11-17 01:00', 'temp_c': 9.4, 'temp_f': 48.9, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 4.3, 'wind_kph': 6.8, 'wind_degree': 153, 'wind_dir': 'SSE', 'pressure_mb': 1019.0, 'pressure_in': 30.09, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 71, 'cloud': 25, 'feelslike_c': 8.6, 'feelslike_f': 47.4, 'windchill_c': 11.8, 'windchill_f': 53.2, 'heatindex_c': 11.7, 'heatindex_f': 53.0, 'dewpoint_c': 7.4, 'dewpoint_f': 45.3, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 6.3, 'gust_kph': 10.1}}\"},\n",
       " {'url': 'https://forecast.weather.gov/MapClick.php?lat=37.77493&lon=-122.419418',\n",
       "  'content': 'Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056°NLon: 122.42694°WElev: 150.0ft. NA. 57°F. 14°C. ... 5am PST Nov 11, 2024-6pm PST Nov 17, 2024 . Forecast Discussion . Additional Resources. ... National Weather Service; San Francisco Bay Area, CA; 21 Grace Hopper Ave, Stop 5; Monterey, CA 93943-5505; Comments? Questions?'},\n",
       " {'url': 'https://forecast.weather.gov/MapClick.php?lat=37.7529881&lon=-122.4174306',\n",
       "  'content': 'Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056°NLon: 122.42694°WElev ... Cloudy, then gradual clearing during the afternoon, with a high near 64. South southwest wind 11 to 17 mph becoming west northwest in the afternoon. Winds could gust as high as 28 mph. Chance of precipitation is 70%. ... 2024-6pm PST Nov 17, 2024'},\n",
       " {'url': 'https://www.timeanddate.com/weather/@z-us-94141',\n",
       "  'content': 'Time Zone News Calendar & Holiday News Time Zones Time Zones Home Time Zone Converter Time Zone Map Time Changes Worldwide Time Zone News Weather Moon Calculator Calculators Calculators Home Home \\xa0 Weather \\xa0 San Francisco Weather Time Zone Weather TodayWeather Hourly14 Day ForecastYesterday/Past WeatherClimate (Averages) Forecast: 60 / 43\\xa0°F Location:San Francisco International AirportCurrent Time:Nov 15, 2024 at 5:01:38 pmLatest Report:Nov 15, 2024 at 3:56 pmVisibility:10\\xa0miPressure:29.96 \"HgHumidity:60%Dew Point:43\\xa0°F Forecast for the next 48 hours ↑ | | * Updated Friday, November 15, 2024 11:03:03 am San Francisco time - Weather by CustomWeather, © 2024 | 14 day forecast, day-by-dayHour-by-hour forecast for next week More weather last week Sun & Moon times precise to the second. Time Zones Weather Calculators'},\n",
       " {'url': 'https://www.wunderground.com/history/daily/us/ca/san-francisco/KCASANFR1753/date/2024-11-17',\n",
       "  'content': 'San Francisco, CA Weather History | Weather Underground Sensor Network Maps & Radar Severe Weather News & Blogs Mobile Apps account_box Log in Go Ad Free_settings_ Settings Sensor NetworkMaps & RadarSevere WeatherNews & BlogsMobile AppsHistorical Weather San Francisco, CA _warning_49 °FClear San Francisco, CA Weather History_star_rate__home_ 45\\xa0°F Metropolitan Oakland Intl Airport Station|Report Report Station Thank you for reporting this station. You are about to report this weather station for bad data. Station Offline Current Station Personal Weather Station Nearby Weather Stations Showing Stations No data recorded No Data Recorded Data Vendors We recognize our responsibility to use data and technology for good. We may use or share your data with our data vendors. Take control of your data. Data Rights'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"what is the weather in SF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\langgraph\\lib\\site-packages\\langsmith\\client.py:5515: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  prompt = loads(json.dumps(prompt_object.manifest))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>agent_scratchpad:</b> The agent does not call a tool just once to get the desired answer, but has a structure that calls tools repeatedly until the desired answer is obtained. Each time you call a tool, what the previous call was like, information about the previous call, and the result are stored in this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'hello how are you'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.fluentu.com/blog/english/english-greetings-expressions/', 'content': 'So “how are ya?” is the same as “how are you?,” and “how are ya going?” is basically the same as “how’s it going?” or “how are you doing?”\\n18.\\nHiya!\\n Usually, these phrases are followed by another question, like “how are you,” “how have you been?” or “what’s new?”\\nSlang Greetings in English\\nSlang greetings are extremely informal, and should only be used with people that you know very well, and feel very comfortable with.\\n Hey\\n,\\nHey man\\nor\\nHi\\nYou can use “hey” and “hi” to greet someone instead of “hello.” Next time you see the person you can show that you remember him or her by saying “it’s nice to see you again” or simply “it’s nice to see you.”\\n 1.\\nGood morning\\n,\\nGood afternoon\\nor\\nGood evening\\nThese are formal ways of saying “hello”, which change depending on the time of day.\\n'}, {'url': 'https://www.fluentu.com/blog/english/how-are-you-esl/', 'content': 'Say “hello” to as many people as you can and see how they answer your “How are you?”\\nOnce you’ve mastered this question, you might be so happy that you answer\\n“perfect”\\nto the next person who asks how you are!\\nDownload:\\n This can be paired with “same old” like this:\\n“How are you doing?”\\n“Oh, you know… same old”\\nI’ve been better\\nWhen there is something wrong, you can use “I’ve been better” as your first response.\\n The difference between “How are you?” and “How are you doing?”\\nThese phrases are very similar, but “how are you?” is slightly more formal, and may be used more commonly when someone is specifically asking about your health or wellbeing.\\n Let’s look at some formal (more polite) answers to “How are you?”\\nYou will use these answers when you’re talking to\\nacquaintances\\nand\\nstrangers\\n. This will lead your friend or relative to ask you\\n“What’s wrong?”\\nor something similar.\\nCould be worse\\nMaybe things aren’t going well lately, but you have some things to be thankful for.\\n'}, {'url': 'https://www.youtube.com/watch?v=Va9hyTtGzzQ', 'content': \"Learn how to use the English greetings 'How are you?' and 'How do you do?' as Dan answers this BBC Learning English learner's question.⭐ For more on this top\"}, {'url': 'https://7esl.com/answer-how-are-you/', 'content': 'in a professional context:\\nFunny Ways to Respond to “How Are You”\\nFinally, here are some fun ways to respond to “how are you?”:\\nDifferent Ways to Answer “How Are You?”\\nLearn more useful\\xa0English\\xa0greetings\\xa0with 30 ways to say Hello.\\nFinal Thoughts\\nThere are many ways to respond to “how are you?” Table of Contents\\nHow to Respond to “How Are You?”\\nPin\\nFormal Ways to Answer “How Are You”\\nHere is a list of the most formal ways you can answer the question “how are you?” and examples of their usage:\\nExamples of their usage include:\\nInformal Ways to Respond to “How Are You”\\nNow let’s look at some of the more informal ways to answer the question “how are you?” Idiomatic Ways to Answer “How Are You”\\nHere are some of the idiomatic ways to respond to “How are you?”\\nThese more colorful responses are best used in lighthearted conversations with close friends and family. I’M PERFCT OK\\nHey\\nComment navigation\\nLeave a Comment Cancel reply\\nComment\\nΔ\\nFree Courses\\nLevel Tests\\nCompany\\nFollow Us'}, {'url': 'https://7esl.com/how-are-you/', 'content': '7ESL » Expressions » Phrases » 40 Other Ways to Ask “How Are You” in English\\n40 Other Ways to Ask “How Are You” in English\\nThe way that you ask someone “how are you?” may vary depending on who is being asked and in what setting the conversation is taking place. Related links:\\n21 thoughts on “40 Other Ways to Ask “How Are You” in English”\\nComment navigation\\nWhat’s new\\nI like lessons\\nThank you\\nGood\\nTHANKS ALOT! How’s it rolling?\\nComment navigation\\nLeave a Comment Cancel reply\\nComment\\nΔ\\nFree Courses\\nLevel Tests\\nCompany\\nFollow Us The list below shows different ways to ask “How Are You” in English that you can use in your daily English conversations.\\n Idiomatic Ways to Ask “How Are You?”\\nThese are playful, casual ways to find out how your buddy or pal is doing.'}]\u001b[0m\u001b[32;1m\u001b[1;3mI'm doing well, thank you!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hello how are you?', 'output': \"I'm doing well, thank you!\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hello how are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in sf'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1731835415, 'localtime': '2024-11-17 01:23'}, 'current': {'last_updated_epoch': 1731834900, 'last_updated': '2024-11-17 01:15', 'temp_c': 9.4, 'temp_f': 48.9, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 4.3, 'wind_kph': 6.8, 'wind_degree': 153, 'wind_dir': 'SSE', 'pressure_mb': 1019.0, 'pressure_in': 30.08, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 74, 'cloud': 25, 'feelslike_c': 8.6, 'feelslike_f': 47.4, 'windchill_c': 11.8, 'windchill_f': 53.2, 'heatindex_c': 11.7, 'heatindex_f': 53.0, 'dewpoint_c': 7.4, 'dewpoint_f': 45.3, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 6.3, 'gust_kph': 10.1}}\"}, {'url': 'https://forecast.weather.gov/MapClick.php?lat=37.77493&lon=-122.419418', 'content': 'Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056°NLon: 122.42694°WElev: 150.0ft. NA. 57°F. 14°C. ... 5am PST Nov 11, 2024-6pm PST Nov 17, 2024 . Forecast Discussion . Additional Resources. ... National Weather Service; San Francisco Bay Area, CA; 21 Grace Hopper Ave, Stop 5; Monterey, CA 93943-5505; Comments? Questions?'}, {'url': 'https://www.timeanddate.com/weather/usa/san-francisco', 'content': 'Current weather in San Francisco and forecast for today, tomorrow, and next 14 days. ... 17 mph: 6 mph: 5 mph: 4 mph: Wind Direction ... 8 mi: 5 mi: 5 mi: 5 mi: 7 mi: Probability of Precipitation: 0%: 0%: 0%: 17%: 1%: 0%: 0%: Amount of Rain---0.06\"---* Updated Tuesday, November 12, 2024 5:03:01 pm San Francisco time - Weather by CustomWeather'}, {'url': 'https://forecast.weather.gov/MapClick.php?lat=37.7529881&lon=-122.4174306', 'content': 'Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056°NLon: 122.42694°WElev ... Cloudy, then gradual clearing during the afternoon, with a high near 64. South southwest wind 11 to 17 mph becoming west northwest in the afternoon. Winds could gust as high as 28 mph. Chance of precipitation is 70%. ... 2024-6pm PST Nov 17, 2024'}, {'url': 'https://www.timeanddate.com/weather/@z-us-94141', 'content': 'Time Zone News Calendar & Holiday News Time Zones Time Zones Home Time Zone Converter Time Zone Map Time Changes Worldwide Time Zone News Weather Moon Calculator Calculators Calculators Home Home \\xa0 Weather \\xa0 San Francisco Weather Time Zone Weather TodayWeather Hourly14 Day ForecastYesterday/Past WeatherClimate (Averages) Forecast: 60 / 43\\xa0°F Location:San Francisco International AirportCurrent Time:Nov 15, 2024 at 5:01:38 pmLatest Report:Nov 15, 2024 at 3:56 pmVisibility:10\\xa0miPressure:29.96 \"HgHumidity:60%Dew Point:43\\xa0°F Forecast for the next 48 hours ↑ | | * Updated Friday, November 15, 2024 11:03:03 am San Francisco time - Weather by CustomWeather, © 2024 | 14 day forecast, day-by-dayHour-by-hour forecast for next week More weather last week Sun & Moon times precise to the second. Time Zones Weather Calculators'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe current temperature in San Francisco is 9.4 degrees Celsius or 48.9 degrees Fahrenheit.  It is Partly cloudy.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'output': 'The current temperature in San Francisco is 9.4 degrees Celsius or 48.9 degrees Fahrenheit.  It is Partly cloudy.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. RAG tool<br>\n",
    "2. ReAct<br>\n",
    "3. custom tool with ReAct agent<br>\n",
    "4. agent code from latest versions(v0.2 and v0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = FAISS.from_documents(documents,embeddings)\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/', 'title': 'LangGraph Studio: The first agent IDE', 'description': 'LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.', 'language': 'en'}, page_content=\"0:00\\n\\n                            /0:20\\n\\n\\n1×\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nConclusionBuilding agentic applications differs from traditional software development. While code editors remain important, new IDEs designed for agents are also needed. LangGraph Studio is a step in this direction, and we're excited to see how it enhances your workflow.For more on LangGraph Studio, check out our documentation. You can also watch a video walkthrough on YouTube if that's more your style. You can\\xa0sign up for LangSmith\\xa0today to try out LangGraph Studio for free.We'd also love your feedback - drop us a line at hello@langchain.dev or on Twitter to share your thoughts.\\n\\n\\nJoin our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            © LangChain Blog 2024\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How to use LangGraph Studio\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "langgraph_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langGraph_search\",\n",
    "    \"Search for information about LangGraph. For any questions about LangGraph, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, langgraph_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langGraph_search` with `{'query': 'how to use langgraph studio'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m0:00\n",
      "\n",
      "                            /0:20\n",
      "\n",
      "\n",
      "1×\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ConclusionBuilding agentic applications differs from traditional software development. While code editors remain important, new IDEs designed for agents are also needed. LangGraph Studio is a step in this direction, and we're excited to see how it enhances your workflow.For more on LangGraph Studio, check out our documentation. You can also watch a video walkthrough on YouTube if that's more your style. You can sign up for LangSmith today to try out LangGraph Studio for free.We'd also love your feedback - drop us a line at hello@langchain.dev or on Twitter to share your thoughts.\n",
      "\n",
      "\n",
      "Join our newsletter\n",
      "Updates from the LangChain team and community\n",
      "\n",
      "\n",
      "Enter your email\n",
      "\n",
      "Subscribe\n",
      "\n",
      "Processing your application...\n",
      "Success! Please check your inbox and click the link to confirm your subscription.\n",
      "Sorry, something went wrong. Please try again.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sign up\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            © LangChain Blog 2024\n",
      "\n",
      "a specific node) halfway through the agent's trajectory. This creates an iterative process, by letting you interact with and manipulate the state at that point in time.While there is much more to explore, we're excited to introduce LangGraph Studio to start with bringing some of the core features of an agent IDE to the world.How to use LangGraph StudioLangGraph Studio is a desktop app, currently available for Apple Silicon. You can download a version here. Support for more platforms is coming soon.After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account. All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta. You can sign up for a LangSmith account here.After downloading LangSmith, you can open a directory. At a bare minimum, this directory needs to contain a Python file with a graph defined in it. Next, you will need to create a langgraph.json file containing details\n",
      "\n",
      "is needed to make the development process easier. Building LLM applications differs from traditional software development, requiring different tooling outside of the traditional code editor.Coding is still important to developing LLM applications — after all, production-ready LangGraph applications have complicated custom logic in the nodes and edges of the graphs that are created. We don't aim to replace code editors but, instead, to augment the development experience with tools tailored for LangGraph applications. LangGraph Studio facilitates this by making it easy to visualize and interact with agent graphs, even if development still primarily happens in code. Visualizing graphs helps developers understand their structure. Furthermore, you can modify an agent result (or the logic underlying a specific node) halfway through the agent's trajectory. This creates an iterative process, by letting you interact with and manipulate the state at that point in time.While there is much more\n",
      "\n",
      "LangGraph Studio: The first agent IDE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Case Studies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In the Loop\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Changelog\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sign in\n",
      "Subscribe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LangGraph Studio: The first agent IDE\n",
      "LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.\n",
      "\n",
      "4 min read\n",
      "Aug 1, 2024\u001b[0m\u001b[32;1m\u001b[1;3mLangGraph Studio is a desktop app, currently available for Apple Silicon.  You can download a version here. Support for more platforms is coming soon. After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account.  All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! how to use langgraph studio?',\n",
       " 'output': 'LangGraph Studio is a desktop app, currently available for Apple Silicon.  You can download a version here. Support for more platforms is coming soon. After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account.  All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta. \\n\\n\\n\\n\\n'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi! how to use langgraph studio?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReAct Agent (Reasoning + Acting):\n",
    "Definition:\n",
    "\n",
    "The ReAct framework combines reasoning and acting in a single loop to handle tasks. The agent uses natural language reasoning (thinking through steps) and task actions (performing tasks like calculations or data retrieval).\n",
    "\n",
    "The agent uses a combination of reasoning steps to guide actions in real-time, using feedback from those actions to further inform the next step in reasoning.\n",
    "\n",
    "How it works:\n",
    "\n",
    "Step 1: The agent receives a question or task.<br>\n",
    "Step 2: It reasons aloud (in natural language) about how to solve it.<br>\n",
    "Step 3: Based on its reasoning, it takes actions (e.g., searching a database, calculating something).<br>\n",
    "Step 4: The results of these actions are integrated into its reasoning and may trigger further actions.<br>\n",
    "Step 5: It repeats the process until it arrives at a solution.<br>\n",
    "Key points:\n",
    "\n",
    "Combines thinking and doing (reasoning and actions).\n",
    "Performs iterative steps, updating its process based on action results.\n",
    "Typically handles complex decision-making scenarios.\n",
    "Example:\n",
    "\n",
    "Original task: “Calculate the total number of apples in a basket if there are 4 baskets and 7 apples in each.”<br>\n",
    "Reasoning: \"I need to multiply 4 by 7 to get the total number of apples.\"<br>\n",
    "Action: Perform the multiplication.<br>\n",
    "Result: \"There are 28 apples.\"<br>\n",
    "Reasoning: \"I am done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=google_search.run,\n",
    "        description=\"useful for when you need to ask with search\",\n",
    "        verbose=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "{tools}\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "Begin!\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = create_react_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=search_agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find information about the Border Gavaskar Trophy 2024 and the teams participating. \n",
      "Action: Intermediate Answer\n",
      "Action Input:  Border Gavaskar Trophy 2024 Teams\u001b[0m\u001b[36;1m\u001b[1;3mThe Border-Gavaskar Trophy 2024-25 is set to feature a highly anticipated five-match Test series between India and Australia, commencing on November 22, 2024.\u001b[0m\u001b[32;1m\u001b[1;3mThought:  I need to find out which team is favored to win.\n",
      "Action: Intermediate Answer\n",
      "Action Input: Border Gavaskar Trophy 2024 Predictions \u001b[0m\u001b[36;1m\u001b[1;3mSo what you're saying is SL > NZ > IND? I expect 6-0 Australia then. India and Australia will battle in a much-awaited five-Test series · India will look to complete a hat-trick of Test series wins on Australian ... India vs Australia Test series predictions. The hosts, Australia will go into the 2024/25 series as slight favourites to regain the Border ... AUS vs IND Playing 11, 1st Test: Explore the predicted playing XI, key players, and team news for the 1st Test of the Border Gavaskar Trophy ... The biggest test series EVER (most likely) kicks off tomorrow between Australia and India. But ... Duration: 11:46. Posted: 2 days ago. ... 2024: \"What are your predictions for Border-Gavaskar Trophy 2024-25? . . (Cricket ... Duration: 0:14. Posted: 2 days ago. Former South African cricketer AB de Villiers has made his predictions for the Border-Gavaskar Trophy 2024-25. I believe India can come out on top with the score line of three one. As the requirement four nil had to qualify for the world test championship ... 32 likes, 3 comments - sportsmint_ on November 21, 2024: \"Border Gavaskar Trophy 2024 ... Duration: 0:44. Posted: 2 days ago.\u001b[0m\u001b[32;1m\u001b[1;3mThought: Based on the information, Australia is predicted to be the slight favorite to win the Border Gavaskar Trophy 2024. \n",
      "\n",
      "Final Answer: Australia is slightly favored to win the Border Gavaskar Trophy 2024. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who has the highest possibility of winning the border gavasker trophy 2024?',\n",
       " 'output': 'Australia is slightly favored to win the Border Gavaskar Trophy 2024.',\n",
       " 'intermediate_steps': [(AgentAction(tool='Intermediate Answer', tool_input='Border Gavaskar Trophy 2024 Teams', log='Thought: I need to find information about the Border Gavaskar Trophy 2024 and the teams participating. \\nAction: Intermediate Answer\\nAction Input:  Border Gavaskar Trophy 2024 Teams'),\n",
       "   'The Border-Gavaskar Trophy 2024-25 is set to feature a highly anticipated five-match Test series between India and Australia, commencing on November 22, 2024.'),\n",
       "  (AgentAction(tool='Intermediate Answer', tool_input='Border Gavaskar Trophy 2024 Predictions', log='Thought:  I need to find out which team is favored to win.\\nAction: Intermediate Answer\\nAction Input: Border Gavaskar Trophy 2024 Predictions '),\n",
       "   'So what you\\'re saying is SL > NZ > IND? I expect 6-0 Australia then. India and Australia will battle in a much-awaited five-Test series · India will look to complete a hat-trick of Test series wins on Australian ... India vs Australia Test series predictions. The hosts, Australia will go into the 2024/25 series as slight favourites to regain the Border ... AUS vs IND Playing 11, 1st Test: Explore the predicted playing XI, key players, and team news for the 1st Test of the Border Gavaskar Trophy ... The biggest test series EVER (most likely) kicks off tomorrow between Australia and India. But ... Duration: 11:46. Posted: 2 days ago. ... 2024: \"What are your predictions for Border-Gavaskar Trophy 2024-25? . . (Cricket ... Duration: 0:14. Posted: 2 days ago. Former South African cricketer AB de Villiers has made his predictions for the Border-Gavaskar Trophy 2024-25. I believe India can come out on top with the score line of three one. As the requirement four nil had to qualify for the world test championship ... 32 likes, 3 comments - sportsmint_ on November 21, 2024: \"Border Gavaskar Trophy 2024 ... Duration: 0:44. Posted: 2 days ago.')]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Who has the highest possibility of winning the border gavasker trophy 2024?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReAct Agent with Custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom tool for the Agent \n",
    "@tool\n",
    "def get_employee_id(name):\n",
    "  \"\"\"\n",
    "  To get employee id, it takes employee name as arguments\n",
    "  name(str): Name of the employee\n",
    "  \"\"\"\n",
    "  fake_employees = {\n",
    "    \"Arjuna\": \"E001\",\n",
    "    \"Bhima\": \"E002\",\n",
    "    \"Chitrasena\": \"E003\",\n",
    "    \"Drona\": \"E004\",\n",
    "    \"Ekalavya\": \"E005\",\n",
    "    \"Pandu\": \"E006\",\n",
    "    \"Nakula\": \"E007\",\n",
    "    \"Sahadeva\": \"E008\",\n",
    "    \"Kunti\": \"E009\",\n",
    "    \"Yudhishthira\": \"E010\"}\n",
    "  \n",
    "  return fake_employees.get(name,\"Employee not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E010'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_employee_id(\"Yudhishthira\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom tool for the Agent \n",
    "@tool\n",
    "def get_employee_salary(employee_id):\n",
    "  \"\"\"\n",
    "  To get the salary of an employee, it takes employee_id as input and return salary\n",
    "  \"\"\"\n",
    "  employee_salaries = {\n",
    "    \"E001\": 56000,\n",
    "    \"E002\": 47000,\n",
    "    \"E003\": 52000,\n",
    "    \"E004\": 61000,\n",
    "    \"E005\": 45000,\n",
    "    \"E006\": 58000,\n",
    "    \"E007\": 49000,\n",
    "    \"E008\": 53000,\n",
    "    \"E009\": 50000,\n",
    "    \"E010\": 55000\n",
    "    }\n",
    "  return employee_salaries.get(employee_id,\"Employee not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\langgraph\\lib\\site-packages\\langsmith\\client.py:5515: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  prompt = loads(json.dumps(prompt_object.manifest))\n"
     ]
    }
   ],
   "source": [
    "# Saved React Prompt in langchain hub, we could manually type the prompt as well.\n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_employee_salary, get_employee_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent,tools=tools,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find Arjuna's employee ID first, then I can use that to get his salary.\n",
      "Action: get_employee_id\n",
      "Action Input: Arjuna\u001b[0m\u001b[33;1m\u001b[1;3mE001\u001b[0m\u001b[32;1m\u001b[1;3mThought: Now that I have Arjuna's employee ID, I can use it to get his salary.\n",
      "Action: get_employee_salary\n",
      "Action Input: E001\u001b[0m\u001b[36;1m\u001b[1;3m56000\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: 56000 \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the Salary of Arjuna?', 'output': '56000'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is the Salary of Arjuna?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Self-Ask with Search Agent:</b><br>\n",
    "\n",
    "<b>Definition:</b><br>\n",
    "This approach allows the AI to ask itself follow-up questions when it doesn't immediately know the answer. It performs a recursive questioning process to break down complex queries into smaller, more manageable ones.\n",
    "Once the AI generates these follow-up questions, it performs an external search (e.g., through Google or an internal database) to gather the necessary information before formulating a response.\n",
    "\n",
    "<b>How it works:</b><br>\n",
    "Step 1: Receive a complex question.<br>\n",
    "Step 2: The agent identifies sub-questions or follow-up questions.<br>\n",
    "Step 3: It performs a search or fetches answers to these questions from external resources (like a web search).<br>\n",
    "Step 4: The answers are aggregated to provide a complete response.<br>\n",
    "\n",
    "<b>Key points:</b><br>\n",
    "Emphasizes question decomposition.<br>\n",
    "Relies on external search for sub-questions.<br>\n",
    "Useful for answering open-ended or broad questions where the answer is not immediately available.<br>\n",
    "\n",
    "<b>Example:</b><br>\n",
    "Original question: “How many moons does Jupiter have?”<br>\n",
    "Sub-question: “What is Jupiter?” (search)<br>\n",
    "Sub-question: “What are moons?” (search)<br>\n",
    "Finally, it retrieves the answer: \"Jupiter has 79 moons.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model='models/embedding-001')\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-1.0-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_self_ask_with_search_agent\n",
    "from langchain_community.tools.tavily_search import TavilyAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=google_search.run,\n",
    "        description=\"useful for when you need to ask with search\",\n",
    "        verbose=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/self-ask-with-search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_self_ask_with_search_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent,tools=tools,verbose=True,handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYes.\n",
      "Follow up: What is the name of the epic in which Arjuna and Karna appear?\u001b[0m\u001b[36;1m\u001b[1;3mIn the Mahabharata, Arjuna is depicted as a skilled archer from an early age, as a student who earns the favour of his preceptor Drona, as the rival of Karna, as the primary adversary of Kauravas, and the betrothed of Draupadi, who became the common wife of the Pandavas.\u001b[0m\u001b[32;1m\u001b[1;3mSo the final answer is: Arjuna\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is a great warrior Arjun or karna?', 'output': 'Arjuna'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Who is a great warrior Arjun or karna?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
